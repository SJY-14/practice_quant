{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-BEATS with TDA Features - Crypto Price Prediction\n",
    "\n",
    "Based on: [Enhancing financial time series forecasting through topological data analysis](https://link.springer.com/article/10.1007/s00521-024-10787-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch pandas scikit-learn ripser matplotlib tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/hiseongmin/-binance-data-collector.git\n",
    "%cd -binance-data-collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Collect Data (Optional - if data not exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect fresh data (takes ~3 min)\n",
    "# Skip if you already have data\n",
    "!pip install requests -q\n",
    "!python main.py --symbol BTCUSDT --days 365 --market futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data\n",
    "!ls -la data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Local imports\n",
    "from ml.features.tda_features import TDAFeatureExtractor\n",
    "from ml.models.nbeats import NBeatsWithTDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "CONFIG = {\n",
    "    'data_path': 'data/BTCUSDT_perp_5m.csv',\n",
    "    'lookback': 96,       # 8 hours (5min * 96)\n",
    "    'horizon': 12,        # 1 hour prediction\n",
    "    'tda_window': 50,     # TDA window size\n",
    "    'batch_size': 128,\n",
    "    'epochs': 100,\n",
    "    'lr': 1e-3,\n",
    "    'hidden_size': 256,\n",
    "    'n_stacks': 2,\n",
    "    'n_blocks': 3,\n",
    "}\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv(CONFIG['data_path'])\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Date range: {df['open_time'].iloc[0]} ~ {df['open_time'].iloc[-1]}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and normalize prices\n",
    "prices = df['close'].values.astype(np.float32)\n",
    "\n",
    "price_scaler = StandardScaler()\n",
    "prices_norm = price_scaler.fit_transform(prices.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(f\"Price range: ${prices.min():.2f} ~ ${prices.max():.2f}\")\n",
    "print(f\"Normalized range: {prices_norm.min():.2f} ~ {prices_norm.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract TDA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Extracting TDA features (this may take a few minutes)...\")\n",
    "\n",
    "tda_extractor = TDAFeatureExtractor(window_size=CONFIG['tda_window'])\n",
    "tda_features = tda_extractor.extract_features(prices_norm)\n",
    "\n",
    "# Pad to match length\n",
    "padding = np.zeros((CONFIG['tda_window'] - 1, 3))\n",
    "tda_features = np.vstack([padding, tda_features]).astype(np.float32)\n",
    "\n",
    "# Normalize\n",
    "tda_scaler = StandardScaler()\n",
    "tda_features = tda_scaler.fit_transform(tda_features)\n",
    "\n",
    "print(f\"TDA features shape: {tda_features.shape}\")\n",
    "print(f\"Features: [Entropy, Amplitude, NumPoints]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize TDA features\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "sample_range = slice(1000, 3000)\n",
    "\n",
    "axes[0].plot(tda_features[sample_range, 0], alpha=0.7)\n",
    "axes[0].set_ylabel('Entropy')\n",
    "axes[0].set_title('TDA Features Over Time')\n",
    "\n",
    "axes[1].plot(tda_features[sample_range, 1], alpha=0.7, color='orange')\n",
    "axes[1].set_ylabel('Amplitude')\n",
    "\n",
    "axes[2].plot(tda_features[sample_range, 2], alpha=0.7, color='green')\n",
    "axes[2].set_ylabel('Num Points')\n",
    "axes[2].set_xlabel('Time')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(prices, tda, lookback, horizon):\n",
    "    X, Y, T = [], [], []\n",
    "    for i in range(lookback, len(prices) - horizon):\n",
    "        X.append(prices[i-lookback:i])\n",
    "        Y.append(prices[i:i+horizon])\n",
    "        T.append(tda[i-1])\n",
    "    return np.array(X), np.array(Y), np.array(T)\n",
    "\n",
    "X, Y, T = create_sequences(\n",
    "    prices_norm, tda_features, \n",
    "    CONFIG['lookback'], CONFIG['horizon']\n",
    ")\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"Y shape: {Y.shape}\")\n",
    "print(f\"T shape: {T.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Val/Test split (70/15/15)\n",
    "n = len(X)\n",
    "train_end = int(0.7 * n)\n",
    "val_end = int(0.85 * n)\n",
    "\n",
    "X_train, X_val, X_test = X[:train_end], X[train_end:val_end], X[val_end:]\n",
    "Y_train, Y_val, Y_test = Y[:train_end], Y[train_end:val_end], Y[val_end:]\n",
    "T_train, T_val, T_test = T[:train_end], T[train_end:val_end], T[val_end:]\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(\n",
    "        torch.FloatTensor(X_train),\n",
    "        torch.FloatTensor(T_train),\n",
    "        torch.FloatTensor(Y_train)\n",
    "    ),\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    TensorDataset(\n",
    "        torch.FloatTensor(X_val),\n",
    "        torch.FloatTensor(T_val),\n",
    "        torch.FloatTensor(Y_val)\n",
    "    ),\n",
    "    batch_size=CONFIG['batch_size']\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(\n",
    "        torch.FloatTensor(X_test),\n",
    "        torch.FloatTensor(T_test),\n",
    "        torch.FloatTensor(Y_test)\n",
    "    ),\n",
    "    batch_size=CONFIG['batch_size']\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NBeatsWithTDA(\n",
    "    lookback=CONFIG['lookback'],\n",
    "    horizon=CONFIG['horizon'],\n",
    "    n_stacks=CONFIG['n_stacks'],\n",
    "    n_blocks=CONFIG['n_blocks'],\n",
    "    hidden_size=CONFIG['hidden_size'],\n",
    "    use_tda=True\n",
    ").to(device)\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {n_params:,}\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x, t, y in train_loader:\n",
    "        x, t, y = x.to(device), t.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x, t)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, t, y in val_loader:\n",
    "            x, t, y = x.to(device), t.to(device), y.to(device)\n",
    "            pred = model(x, t)\n",
    "            val_loss += criterion(pred, y).item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{CONFIG['epochs']} - Train: {train_loss:.6f}, Val: {val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training progress\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(val_losses, label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Progress')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.eval()\n",
    "\n",
    "# Predict on test set\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, t, y in test_loader:\n",
    "        x, t = x.to(device), t.to(device)\n",
    "        pred = model(x, t)\n",
    "        all_preds.append(pred.cpu().numpy())\n",
    "        all_targets.append(y.numpy())\n",
    "\n",
    "preds = np.concatenate(all_preds)\n",
    "targets = np.concatenate(all_targets)\n",
    "\n",
    "print(f\"Predictions shape: {preds.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "mse = np.mean((preds - targets) ** 2)\n",
    "mae = np.mean(np.abs(preds - targets))\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Direction accuracy\n",
    "pred_dir = np.sign(preds[:, -1] - preds[:, 0])\n",
    "true_dir = np.sign(targets[:, -1] - targets[:, 0])\n",
    "dir_acc = np.mean(pred_dir == true_dir) * 100\n",
    "\n",
    "print(\"=\" * 40)\n",
    "print(\"TEST RESULTS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"MSE:  {mse:.6f}\")\n",
    "print(f\"RMSE: {rmse:.6f}\")\n",
    "print(f\"MAE:  {mae:.6f}\")\n",
    "print(f\"Direction Accuracy: {dir_acc:.2f}%\")\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Predictions vs Actual (first step)\n",
    "n_show = 300\n",
    "axes[0, 0].plot(targets[:n_show, 0], label='Actual', alpha=0.7)\n",
    "axes[0, 0].plot(preds[:n_show, 0], label='Predicted', alpha=0.7)\n",
    "axes[0, 0].set_title('Predictions vs Actual (1-step ahead)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# 2. Scatter plot\n",
    "axes[0, 1].scatter(targets[:, 0], preds[:, 0], alpha=0.3, s=5)\n",
    "axes[0, 1].plot([targets.min(), targets.max()], [targets.min(), targets.max()], 'r--')\n",
    "axes[0, 1].set_xlabel('Actual')\n",
    "axes[0, 1].set_ylabel('Predicted')\n",
    "axes[0, 1].set_title('Scatter Plot')\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# 3. Error distribution\n",
    "errors = preds[:, 0] - targets[:, 0]\n",
    "axes[1, 0].hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].axvline(0, color='r', linestyle='--')\n",
    "axes[1, 0].set_xlabel('Prediction Error')\n",
    "axes[1, 0].set_title('Error Distribution')\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# 4. Full horizon prediction example\n",
    "sample_idx = 100\n",
    "axes[1, 1].plot(range(CONFIG['horizon']), targets[sample_idx], 'b-o', label='Actual')\n",
    "axes[1, 1].plot(range(CONFIG['horizon']), preds[sample_idx], 'r-o', label='Predicted')\n",
    "axes[1, 1].set_xlabel('Steps Ahead (5min each)')\n",
    "axes[1, 1].set_ylabel('Price (normalized)')\n",
    "axes[1, 1].set_title(f'Full Horizon Prediction (Sample {sample_idx})')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Compare with Baseline (No TDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline model without TDA\n",
    "print(\"Training baseline model (without TDA)...\")\n",
    "\n",
    "baseline_model = NBeatsWithTDA(\n",
    "    lookback=CONFIG['lookback'],\n",
    "    horizon=CONFIG['horizon'],\n",
    "    n_stacks=CONFIG['n_stacks'],\n",
    "    n_blocks=CONFIG['n_blocks'],\n",
    "    hidden_size=CONFIG['hidden_size'],\n",
    "    use_tda=False  # No TDA\n",
    ").to(device)\n",
    "\n",
    "baseline_optimizer = torch.optim.AdamW(baseline_model.parameters(), lr=CONFIG['lr'])\n",
    "\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    baseline_model.train()\n",
    "    for x, t, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        baseline_optimizer.zero_grad()\n",
    "        pred = baseline_model(x, None)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        baseline_optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{CONFIG['epochs']}\")\n",
    "\n",
    "print(\"Baseline training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "baseline_model.eval()\n",
    "baseline_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, t, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        pred = baseline_model(x, None)\n",
    "        baseline_preds.append(pred.cpu().numpy())\n",
    "\n",
    "baseline_preds = np.concatenate(baseline_preds)\n",
    "\n",
    "# Metrics\n",
    "baseline_mse = np.mean((baseline_preds - targets) ** 2)\n",
    "baseline_dir = np.sign(baseline_preds[:, -1] - baseline_preds[:, 0])\n",
    "baseline_dir_acc = np.mean(baseline_dir == true_dir) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"COMPARISON: TDA vs No-TDA\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Metric':<20} {'With TDA':<15} {'Without TDA':<15}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'MSE':<20} {mse:<15.6f} {baseline_mse:<15.6f}\")\n",
    "print(f\"{'Direction Acc':<20} {dir_acc:<15.2f}% {baseline_dir_acc:<15.2f}%\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nTDA Improvement: {baseline_mse - mse:.6f} MSE, {dir_acc - baseline_dir_acc:.2f}% Direction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save complete model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'price_scaler_mean': price_scaler.mean_,\n",
    "    'price_scaler_scale': price_scaler.scale_,\n",
    "    'tda_scaler_mean': tda_scaler.mean_,\n",
    "    'tda_scaler_scale': tda_scaler.scale_,\n",
    "}, 'nbeats_tda_complete.pt')\n",
    "\n",
    "print(\"Model saved to nbeats_tda_complete.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
