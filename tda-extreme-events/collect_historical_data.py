"""
ë°”ì´ë‚¸ìŠ¤ ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
Binance Historical Data Collector

Usage:
    python collect_historical_data.py [--days 365] [--symbol BTCUSDT]
"""
import requests
import pandas as pd
from datetime import datetime, timedelta
import time
import argparse
import os

def fetch_binance_klines(symbol='BTCUSDT', interval='5m', market='futures', limit=1500, end_time=None):
    """
    ë°”ì´ë‚¸ìŠ¤ ìº”ë“¤ ë°ì´í„° ìˆ˜ì§‘

    Parameters:
    -----------
    symbol : str
        ê±°ë˜ ìŒ (ê¸°ë³¸ê°’: BTCUSDT)
    interval : str
        ìº”ë“¤ ê°„ê²© (ê¸°ë³¸ê°’: 5m)
    market : str
        ì‹œì¥ ì¢…ë¥˜ 'futures' ë˜ëŠ” 'spot'
    limit : int
        í•œ ë²ˆì— ê°€ì ¸ì˜¬ ìº”ë“¤ ìˆ˜ (ìµœëŒ€ 1500)
    end_time : datetime
        ë ì‹œê°„ (Noneì´ë©´ í˜„ì¬)

    Returns:
    --------
    list : ìº”ë“¤ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    if market == 'futures':
        url = "https://fapi.binance.com/fapi/v1/klines"
    else:
        url = "https://api.binance.com/api/v3/klines"

    params = {
        'symbol': symbol,
        'interval': interval,
        'limit': limit
    }

    if end_time:
        params['endTime'] = int(end_time.timestamp() * 1000)

    try:
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"  âŒ API request failed: {e}")
        return []

def collect_data(symbol='BTCUSDT', interval='5m', market='futures', days=365):
    """
    ê³¼ê±° ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ DataFrameìœ¼ë¡œ ë°˜í™˜

    Parameters:
    -----------
    symbol : str
        ê±°ë˜ ìŒ
    interval : str
        ìº”ë“¤ ê°„ê²©
    market : str
        ì‹œì¥ ì¢…ë¥˜
    days : int
        ìˆ˜ì§‘í•  ê³¼ê±° ì¼ìˆ˜

    Returns:
    --------
    pd.DataFrame : ìˆ˜ì§‘ëœ ë°ì´í„°
    """
    print(f"ğŸ“¥ Collecting {market} data for {symbol}...")
    print(f"  Interval: {interval}")
    print(f"  Period: {days} days")

    all_data = []
    end_time = datetime.now()

    # í•„ìš”í•œ ë°˜ë³µ íšŸìˆ˜ ê³„ì‚°
    # 5ë¶„ ê°„ê²© â†’ 1ì¼ = 288 ìº”ë“¤, 1500ê°œì”© ê°€ì ¸ì˜¤ë©´ ì•½ 5.2ì¼ì¹˜
    candles_per_day = (24 * 60) // 5  # 5ë¶„ ê°„ê²©
    total_candles_needed = days * candles_per_day
    iterations = (total_candles_needed // 1500) + 1

    print(f"  Total candles needed: ~{total_candles_needed}")
    print(f"  Fetching in {iterations} batches...\n")

    for i in range(iterations):
        print(f"  Batch {i+1}/{iterations}...", end=' ')

        klines = fetch_binance_klines(symbol, interval, market, 1500, end_time)

        if not klines:
            print("No data")
            break

        # ë°ì´í„° ì²˜ë¦¬
        batch_data = []
        for k in klines:
            candle = {
                'open_time': pd.to_datetime(k[0], unit='ms'),
                'open': float(k[1]),
                'high': float(k[2]),
                'low': float(k[3]),
                'close': float(k[4]),
                'volume': float(k[5]),
                'buy_volume': float(k[9]),  # taker_buy_base_volume
            }

            # Buy/Sell volume ê³„ì‚°
            candle['sell_volume'] = candle['volume'] - candle['buy_volume']
            candle['volume_delta'] = candle['buy_volume'] - candle['sell_volume']

            batch_data.append(candle)

        all_data.extend(batch_data)
        print(f"âœ… {len(batch_data)} candles")

        # ë‹¤ìŒ ë°°ì¹˜ë¥¼ ìœ„í•´ end_time ì—…ë°ì´íŠ¸
        if batch_data:
            end_time = batch_data[0]['open_time']

        # Rate limiting (ë°”ì´ë‚¸ìŠ¤ API ì œí•œ ì¤€ìˆ˜)
        time.sleep(0.5)

        # ëª©í‘œ ì¼ìˆ˜ë§Œí¼ ìˆ˜ì§‘í–ˆìœ¼ë©´ ì¢…ë£Œ
        if len(all_data) >= total_candles_needed:
            print(f"  Target reached ({len(all_data)} candles)")
            break

    # DataFrame ìƒì„± ë° ì •ë ¬
    df = pd.DataFrame(all_data)

    if len(df) == 0:
        print("  âŒ No data collected!")
        return pd.DataFrame()

    df = df.sort_values('open_time').reset_index(drop=True)

    # ì¤‘ë³µ ì œê±°
    df = df.drop_duplicates(subset='open_time', keep='first')

    # CVD (Cumulative Volume Delta) ê³„ì‚°
    df['cvd'] = df['volume_delta'].cumsum()

    print(f"\n  âœ… Collected {len(df)} candles")
    print(f"  Date range: {df['open_time'].min()} to {df['open_time'].max()}")
    print(f"  Duration: {(df['open_time'].max() - df['open_time'].min()).days} days")

    return df

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='Binance Historical Data Collector')
    parser.add_argument('--days', type=int, default=365,
                       help='Number of days to collect (default: 365)')
    parser.add_argument('--symbol', type=str, default='BTCUSDT',
                       help='Trading pair symbol (default: BTCUSDT)')
    parser.add_argument('--interval', type=str, default='5m',
                       help='Candle interval (default: 5m)')
    parser.add_argument('--output-dir', type=str, default='../binance-data-collector',
                       help='Output directory (default: ../binance-data-collector)')

    args = parser.parse_args()

    print("="*80)
    print("ğŸ“Š BINANCE HISTORICAL DATA COLLECTOR")
    print("="*80)
    print(f"Symbol: {args.symbol}")
    print(f"Interval: {args.interval}")
    print(f"Period: {args.days} days")
    print(f"Output: {args.output_dir}")
    print("="*80)
    print()

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(args.output_dir, exist_ok=True)

    try:
        # Futures ë°ì´í„° ìˆ˜ì§‘
        print("\n1ï¸âƒ£ FUTURES DATA")
        print("-"*80)
        df_futures = collect_data(args.symbol, args.interval, 'futures', args.days)

        if len(df_futures) > 0:
            output_path = os.path.join(args.output_dir, f'{args.symbol}_perp_{args.interval}.csv')
            df_futures.to_csv(output_path, index=False)
            print(f"ğŸ’¾ Futures data saved to: {output_path}")
            print(f"   File size: {os.path.getsize(output_path) / 1024 / 1024:.2f} MB")
        else:
            print("âš ï¸ No futures data collected")

        print()

        # Spot ë°ì´í„° ìˆ˜ì§‘
        print("2ï¸âƒ£ SPOT DATA")
        print("-"*80)
        df_spot = collect_data(args.symbol, args.interval, 'spot', args.days)

        if len(df_spot) > 0:
            output_path = os.path.join(args.output_dir, f'{args.symbol}_spot_{args.interval}.csv')
            df_spot.to_csv(output_path, index=False)
            print(f"ğŸ’¾ Spot data saved to: {output_path}")
            print(f"   File size: {os.path.getsize(output_path) / 1024 / 1024:.2f} MB")
        else:
            print("âš ï¸ No spot data collected")

        print()
        print("="*80)
        print("âœ… DATA COLLECTION COMPLETE!")
        print("="*80)

        # ìš”ì•½ ì¶œë ¥
        if len(df_futures) > 0 and len(df_spot) > 0:
            print("\nğŸ“Š Summary:")
            print(f"  Futures candles: {len(df_futures):,}")
            print(f"  Spot candles:    {len(df_spot):,}")
            print(f"  Futures range:   {df_futures['open_time'].min()} to {df_futures['open_time'].max()}")
            print(f"  Spot range:      {df_spot['open_time'].min()} to {df_spot['open_time'].max()}")
            print(f"\nğŸ¯ Next step: python realtime_predictor.py")

    except KeyboardInterrupt:
        print("\n\nâš ï¸ Collection interrupted by user")
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
